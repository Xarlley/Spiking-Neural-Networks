# Spiking Yolo：2018-2025

## I. 执行摘要

虽然SNNs在图像分类等较简单的任务中显示出潜力，但将其应用于物体检测等更复杂的、重度依赖回归的问题，在历史上一直是一项艰巨的挑战。本报告对脉冲YOLO（Spiking YOLO）的演进进行了详尽的调研和细致的分析。**脉冲YOLO是一个模型家族**，它将非常成功的“你只看一次”（YOLO）物体检测框架应用于SNN领域。脉冲YOLO的发展轨迹是一个引人注目的案例，展示了一项新兴技术的成熟过程，描绘了从最初的概念验证到开发出复杂的、高性能架构的路线图。这一历程的标志是克服了重大的技术障碍，包括过高的**推理延迟**、**将ANN架构转换为脉冲域**的挑战（如“脉冲退化”现象），以及基于脉冲的计算中固有的**信息保真度损失**。

这一历程始于Spiking-YOLO (AAAI 2020)，这是一项开创性的工作，首次通过ANN到SNN的转换方法证明了基于SNN的物体检测的可行性。随后，**EMS-YOLO (ICCV 2023)** 带来了关键的范式转变，它引入了使用代理梯度的直接端到端训练方法，解决了其前身令人 debilitating 的延迟问题，使脉冲检测器在实践中变得可行。此后，该领域进入了成熟和优化的阶段，以**SpikeYOLO (ECCV 2024)** 和**SpikingYOLOX (AAAI 2025)** 等模型为代表。这些近期的工作专注于SNN原生设计原则，引入了专门的神经元模型和架构创新，以解决量化误差和特征表示有限等二阶问题。这一演进弧线展示了一个清晰的进程：该领域已经从仅仅证明脉冲物体检测是可能的，发展到设计出与ANN对应物越来越有竞争力的解决方案，为新一代高能效计算机视觉系统铺平了道路。

## II. 脉冲物体检测的起源：ANN到SNN的转换

最初将SNNs应用于物体检测这一复杂任务的尝试，并非通过新颖的、SNN原生的架构，而是通过一个转换过程。ANN到SNN的转换方法为利用传统深度学习的大量研究成果提供了第一条可行的途径，在已被充分理解的ANN模拟域和新兴的、事件驱动的SNN世界之间架起了一座桥梁。这种方法虽然最终有其局限性，但在建立该领域和定义驱动未来创新的初始挑战集方面起到了关键作用。

### 2.1. 方法论：连接模拟世界与脉冲世界

ANN到SNN转换背后的核心概念是，将一个预训练好的、高性能的ANN转换为一个功能上等效的SNN。这个过程通常包括两个主要步骤。首先，复制ANN的架构，但将标准的激活函数（如修正线性单元ReLU）替换为脉冲神经元模型，最常见的是泄漏积分发放（LIF）或积分发放（IF）神经元。其次，将ANN在训练过程中学到的权重转移到SNN中。其基本原理是在ANN神经元的连续值激活与脉冲神经元在时间上的平均发放率之间建立等价关系。本质上，ANN中较高的激活值应对应于SNN中神经元在给定时间窗口内更高的脉冲发放频率。

然而，这种转换充满了技术挑战。主要困难在于将一个连续系统转换为一个离散的、时序的系统时产生的固有近似误差。这种不匹配通常导致与原始ANN相比性能显著下降。为了实现对ANN激活的稳定和准确的近似，SNN必须运行大量的推理时间步，以使其神经元的发放率收敛。这种对高延迟的要求直接与使用SNNs的主要动机——快速、低功耗的计算——相矛盾。因此，出现了一个根本性的权衡：提高准确性需要更长的推理时间，这反过来又增加了延迟和能耗，削弱了脉冲范式的优势。

### 2.2. 基础框架：Spiking-YOLO (AAAI 2020)

尽管存在这些挑战，转换方法还是为该领域的第一个重大突破提供了必要的基础。发表于AAAI 2020的Spiking-YOLO是第一个被记录的、成功应用于物体检测这一重度依赖回归任务的深度SNN，这是一个重要的里程碑，将SNN的应用范围从简单的分类扩展到了更广的领域。该模型基于对Tiny YOLO的转换，后者是流行的YOLO架构的一个轻量级和快速的变体，使其成为探索高能效实现的合适候选者。

Spiking-YOLO的作者识别并解决了几个特定于转换物体检测模型的关键问题。他们的工作引入了两项关键的技术创新：

1. 通道级归一化 (Channel-wise Normalization): 在用于分类任务的ANN到SNN转换中，标准的权重归一化技术被证明不足以应对物体检测器更深、更复杂的架构。它们通常会导致深层网络中出现“死神经元”（从不发放脉冲的神经元）或极低的发放率，从而阻止了信息在网络中的流动。为了解决这个问题，Spiking-YOLO引入了一种更细粒度的、通道级的归一化方法。该技术确保了整个网络中的神经元都能保持适当且足够高的发放率，即使在深度SNN中也能实现快速准确的信息传输。
2. 带不平衡阈值的有符号神经元 (Signed Neuron with Imbalanced Threshold): 许多YOLO模型的一个重要架构组件是Leaky-ReLU激活函数。在此工作之前，没有有效且准确的方法在SNN域内实现此功能。作者提出了一种新颖的神经元模型，即“带不平衡阈值的有符号神经元”，它为Leaky-ReLU提供了一个有效且高效的基于SNN的等效实现，保留了原始ANN功能的关键元素。

这些创新使得Spiking-YOLO在当时取得了显著的成果。在PASCAL VOC和MS COCO等标准物体检测基准上，转换后的SNN实现了与原始Tiny YOLO模型高度可比（高达98%）的性能。然而，这种准确性是以高昂的延迟为代价的。为了达到其峰值性能，该模型需要极大量的推理时间步，通常在2,000到高达8,000之间。这种高延迟使得该模型对于YOLO架构通常擅长的实时应用来说不切实际，并鲜明地揭示了ANN到SNN转换范式在处理复杂任务时的根本效率瓶颈。

论文: Kim, S., Park, S., Lee, B., & Yoon, S. (2020). [Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object Detection.](https://ojs.aaai.org/index.php/AAAI/article/view/6787) In Proceedings of the AAAI Conference on Artificial Intelligence.

代码: 一个基于该论文原理的公开PyTorch实现可在 [https://github.com/cwq159/PyTorch-Spiking-YOLOv3](https://github.com/cwq159/PyTorch-Spiking-YOLOv3) 找到。

该模型对ANN到SNN转换的依赖意味着其核心计算逻辑继承自一个模拟的、基于帧的世界，并非为SNN的时序性、事件驱动的特性而原生设计。转换的核心机制——使用离散脉冲在许多时间步上的发放率来近似一个单一的、连续的激活值——本质上是一个高延迟的过程。为了获得对ANN内部表示的高保真度近似，需要大量的时序样本（即时间步）。 这就产生了一个直接且不可避免的权衡：任何试图通过改善发放率近似来提高模型准确性的尝试，都必然需要增加时间步的数量。这反过来又会增加延迟和总能耗，直接削弱了SNNs的核心承诺。

因此，虽然Spiking-YOLO是一项奠基性的成就，但它也明确地表明，对于实现实用的、低延迟的物体检测而言，ANN到SNN的转换方法很可能是一个演化上的死胡同。它展示了什么是可能的，但更重要的是，它突显了对一种全新训练范式的迫切需求——一种不受限于速率编码近似，并能在低延迟状态下高效运行的范式。这一认识直接推动了该领域后续向直接训练方法的必要转变。

## III. 范式转变：脉冲检测器的直接训练

要释放SNNs在复杂任务上的真正潜力，需要一种新的方法，而不仅仅是ANNs近似物的方法。这导致了直接训练的采用，这是一种从零开始、端到端地训练SNNs的范式。

### 3.1. 方法论：在不可微网络中进行可微训练

直接训练SNN面临着一个重大的理论挑战。脉冲神经元的核心计算涉及一个发放事件，该事件在其内部膜电位超过一个固定阈值时发生。这个事件在数学上由亥维赛德阶跃函数描述，这是一个非连续且不可微的操作。作为现代深度学习基石的标准反向传播算法，依赖于基于梯度的优化，这要求网络中的所有操作都是可微的。 脉冲的“全或无”特性意味着其导数几乎处处为零，在阈值处未定义，从而在训练期间有效地阻断了梯度的流动。

解决这一僵局的方法是**代理梯度（surrogate gradient）** 方法。 在前向传播过程中，SNN照常运行，神经元整合输入并发放离散的、不可微的脉冲。然而，在反向传播（backpropagation）过程中，这个硬性的、不可微的阶跃函数被一个平滑的、连续的近似函数——一个“代理”函数——所取代。这个代理函数，通常是一个快速S型函数或类似的平滑曲线，具有明确定义的导数，可用于近似真实梯度。 通过“假装”神经元的激活函数是可微的，这项技术使得误差梯度能够回流通过网络，从而可以使用像Adam这样的标准梯度优化器从随机初始化开始训练SNN的权重。这种方法有效地将SNN视为一种特殊形式的循环神经网络（RNN），其中状态（膜电位）在每个时间步更新，误差则通过时间反向传播（BPTT）。

### 3.2. 开创性框架：EMS-YOLO (ICCV 2023)

使用代理梯度进行直接训练的理论基础，为脉冲物体检测的下一次重大飞跃奠定了基础。发表于ICCV 2023的EMS-YOLO是首个成功将此方法应用于训练深度SNN进行物体检测的开创性框架。这项工作代表了该领域摆脱ANN到SNN转换束缚所必需的关键范式转变，标志着高性能脉冲检测器现代纪元的开始。

EMS-YOLO引入了几个对其成功至关重要的关键技术创新：

1. EMS-ResNet (高能效多尺度脉冲残差网络): 训练深度SNN的一个主要挑战是性能下降以及梯度消失或爆炸的风险，这个问题在ANNs中由残差连接（ResNets）解决。然而，先前为分类任务设计的深度SNNs通常在捷径连接（shortcut path）上使用非脉冲操作，如平均池化或标准卷积。 虽然这些操作在维持梯度流方面很有效，但它们的计算成本高、能耗大，削弱了SNN的效率。EMS-YOLO引入了一种新颖的、全脉冲的残差块，其中每个组件，包括捷径连接，都由脉冲神经元实现。这种设计最大化了能源效率，并确保了与事件驱动的神经形态硬件的完全兼容。
2. 实现深度SNN训练: 该论文不仅提供了经验证明，还提供了理论分析，证明了EMS-ResNet架构可以有效缓解反向传播过程中的梯度消失和爆炸问题。这一理论支持至关重要，因为它为将直接训练的SNNs扩展到物体检测等复杂任务所需的深度提供了信心，而这在以前被认为是不切实际的。

这一新范式的影响是立竿见影且深远的。EMS-YOLO在仅4个时间步的极低延迟下，实现了与其等效ANN架构相当的性能。这比Spiking-YOLO所需的数千个时间步有了惊人的改进，有效地解决了困扰该领域的主要瓶颈。此外，该模型在传统的静态图像数据集（MS COCO）和基于事件的神经形态数据集（Prophesee GEN1）上都取得了优异的性能，展示了直接训练的SNNs在处理时空数据方面的原生优势。   

论文: Su, Q., et al. (2023). [Deep Directly-Trained Spiking Neural Networks for Object Detection.](https://arxiv.org/abs/2307.11411) In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV).    

代码: 官方实现可在 [https://github.com/BICLab/EMS-YOLO](https://github.com/BICLab/EMS-YOLO) 找到。

### 3.3. 释放潜力，发现新问题

EMS-YOLO通过解决推理延迟这一关键问题，将基于SNN的物体检测转变为一项实践上可行的技术。然而，在解决这一首要瓶颈的同时，这一突破无意中也暴露了一类新的、更微妙的二阶挑战，这些挑战与架构保真度和脉冲域中信息表示的性质有关。研究界的焦点，开始从“如何让它工作”这个基本问题，转向“如何让它良好地工作”这个更细致的问题。

直接训练深度SNNs的能力使研究人员能够更清楚地观察到脉冲动态与ANNs连续激活之间的关键差异。这些差异以前被转换过程的高延迟和近似误差所掩盖，现在则清晰地显现出来。两个关键问题成为该领域下一个主要障碍。

首先，研究人员开始认识到，仅仅将现代ANNs中的复杂架构模块直接移植到脉冲域，并不能保证成功。正如后续SpikeYOLO论文的作者后来所阐述的，为ANNs设计的复杂模块可能会在SNNs中导致不可预见的有害现象，例如 **“脉冲退化”**（spike degradation）。这是一种由于兴奋、抑制和阈值处理之间复杂的相互作用，导致基于脉冲的信息流在网络的深层实际上停止，从而削弱其学习能力的状况。 虽然EMS-YOLO基于ResNet的主干网络是一个成功的起点，但最先进的YOLO版本中更复杂、更优化的架构带来了更大的挑战。

其次，脉冲神经元计算的基本行为——将连续的内部状态（膜电位）量化为二元输出（一个脉冲或无脉冲）——被认为是信息丢失的一个主要来源。虽然这种二元通信是SNN能源效率的来源，但它也代表了一个显著的信息瓶颈。研究发现，这种精度损失对物体检测尤其有害，因为该任务严重依赖高精度回归来准确预测边界框坐标。

因此，EMS-YOLO的突破虽然解决了一个主要问题，却将研究对话提升到了一个更高的复杂层次。学术界的焦点从训练方法本身转向了架构和神经元模型的协同设计，这些设计需要为脉冲域的独特约束和机遇进行优化。这为下一波创新铺平了道路，学界将寻求通过创建真正的SNN原生解决方案来完善直接训练范式。

## IV. 直接训练范式的成熟与优化

随着直接训练被确立为主要且最有效的方法论，脉冲YOLO领域进入了一个成熟阶段。研究工作从基础性突破转向了旨在缩小与最先进ANNs性能差距的针对性优化。直接建立在EMS-YOLO奠定的基础之上的下一代模型，代表了对SNN特定挑战的更深刻理解。这些工作的特点是向SNN原生设计迈进，其中网络架构和基础神经元模型都被重新构想，以解决架构不匹配和信息丢失等细微问题。

### 4.1. SpikeYOLO (ECCV 2024): 优化架构与神经元动态

在ECCV 2024上发表的SpikeYOLO是直接训练范式的直接思想继承者，其明确设计目标是超越先前SNN检测器（如EMS-YOLO）设定的性能基准。 该工作的核心贡献是一种复杂的、双管齐下的方法，同时解决了在直接训练的深度SNNs中变得明显的关键架构和神经元局限性。   

SpikeYOLO的作者提出了两项关键的技术创新：

SNN原生架构 (SpikeYOLO): 研究人员的一个关键观察是，现代ANN检测器中日益复杂的模块，例如YOLOv8中的C2F（带有2个卷积的跨阶段局部网络）块，从根本上不适合脉冲域。当直接转换时，这些复杂的设计可能导致“脉冲退化”现象，即深层神经元停止发放脉冲，从而有效地中断了信息流。 解决方案不是尝试直接的一对一映射，而是设计一种新的、简化的架构。SpikeYOLO架构保留了YOLOv8的高层宏观结构，但用受近期脉冲Transformer模型效率和鲁棒性启发的“元SNN块”替换了其复杂的内部块。这种SNN原生设计被证明对于深度脉冲网络更加稳定和有效。   

整数泄漏积分发放 (I-LIF) 神经元: SpikeYOLO针对的第二个主要挑战是由量化误差导致的显著信息丢失。当神经元的连续膜电位被压缩成一个二元脉冲时，就会发生这种情况，这个过程对准确预测边界框所需的高精度回归尤其有害。为了解决这个问题，该论文提出了一种新颖的I-LIF神经元。该模型在训练阶段创新地使用整数值计算，这有助于减少量化误差并提高模型的准确性。在推理过程中，它保持了SNNs的高能效、脉冲驱动的特性，从而实现了两全其美：训练时精度更高，部署时功耗更低。   

这两项创新的结合带来了性能上的巨大飞跃。在具有挑战性的MS COCO数据集上，SpikeYOLO实现的平均精度均值（mAP）显著高于之前的SNN最新水平，mAP@50提升了+15.0%，mAP@50:95提升了+18.7%。 这为基于SNN的物体检测设定了新的性能基准，并展示了专门为脉冲域设计解决方案的力量。   

论文: Luo, Z., et al. (2024). [Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection](https://arxiv.org/pdf/2407.20708). In Proceedings of the European Conference on Computer Vision (ECCV).    

代码: [https://github.com/BICLab/SpikeYOLO](https://github.com/BICLab/SpikeYOLO) 

### 4.2. SpikingYOLOX (AAAI 2025): 扩展特征表示与感受野

#### 4.2.1 EAS-SNN (ECCV 2024): SpikingYOLOX (AAAI 2025)的原型

摘要：在本研究中，我们发现脉冲神经元的神经动力学与理想时间事件采样器的行为紧密相关。受此启发，我们提出了一种新颖的自适应采样模块，该模块利用增强了时间记忆的循环卷积脉冲神经网络 (SNN)，从而构建一个完全端到端的可学习事件检测框架。此外，我们引入了残差电位丢弃 (RPD) 和脉冲感知训练 (SAT) 来调节电位分布，并解决脉冲采样模块中遇到的性能下降问题。在神经形态检测数据集上的实证评估表明，我们的方法优于现有的最先进的脉冲方法，并且参数和时间步长显著减少。例如，我们的方法在 Gen1 数据集上实现了 4.4% 的 mAP 提升，同时所需的参数减少了 38%，时间步长仅为 3 个。此外，通过在传统非脉冲模型上的进一步验证，我们的自适应采样方法的适用性和有效性已扩展到 SNN 之外。

论文: [EAS-SNN: End-to-End Adaptive Sampling and Representation for Event-Based Detection with Recurrent Spiking Neural Networks](https://link.springer.com/content/pdf/10.1007/978-3-031-73027-6_18.pdf?pdf=inline+link)

代码：[https://github.com/Windere/EAS-SNN](https://github.com/Windere/EAS-SNN)

#### 4.2.2 SpikingYOLOX (AAAI 2025): 扩展特征表示与感受野

计划在AAAI 2025上发表的SpikingYOLOX代表了直接训练范式演进的另一个分支。SpikeYOLO专注于架构稳定性和减少量化误差，而SpikingYOLOX则解决了另一组同样重要的二阶问题：二元脉冲的有限表达能力和卷积架构的受限感受野。 这项工作是首次将SNN原理与高性能的YOLOX架构相结合，其创新点集中于增强网络表示复杂特征和捕捉全局场景上下文的能力。   

SpikingYOLOX引入了两项主要的技术创新：

三元有符号脉冲神经元 (Ternary Signed Spiking Neuron): 传统的SNNs基于二元脉冲运行，神经元的输出要么是‘1’（发放），要么是‘0’（不发放）。这种有限的信号传输能力可能成为表示复杂特征的瓶颈。SpikingYOLOX引入了一种新颖的神经元模型，能够产生三种不同的状态：‘-1’（抑制性脉冲）、‘0’（无脉冲）和‘1’（兴奋性脉冲）。这种三元信号传输提供了更丰富、更具表现力的特征表示，使网络能够学习数据中更复杂的模式，从而提高其整体检测准确性。   

快速傅里叶卷积 (Fast Fourier Convolution, FFC): 标准卷积神经网络（以及基于它们的SNNs）一个众所周知的局限性是其固有的局部感受野。每个神经元只处理来自前一层输入的一小块区域的信息。这在物体检测中可能是一个缺点，因为理解整个场景的全局上下文对于正确定位和识别物体通常至关重要。为了克服这一点，SpikingYOLOX在其架构中集成了快速傅里叶卷积。通过在频域中操作，FFC可以高效地计算具有全局感受野的卷积，使得每个输出特征都能受到每个输入像素的影响。该论文引入了新颖的、与SNN兼容的模块，如CSP-FFC-SNN和SPP-SNN，以有效地整合这一强大机制。   

通过在特征表示和上下文推理方面的这两项双重创新，SpikingYOLOX论文声称在现有的基于SNN的物体检测器中达到了最先进的性能，进一步推动了直接训练脉冲网络的可能性边界。   

论文: Miao, W., et al. (2025). [SpikingYOLOX: Improved YOLOX Object Detection with Fast Fourier Convolution and Spiking Neural Networks](https://dl.acm.org/doi/10.1609/aaai.v39i2.32137). In Proceedings of the AAAI Conference on Artificial Intelligence.    

代码: [https://github.com/Windere/Spiking-YOLOX](https://github.com/Windere/Spiking-YOLOX)   

### 4.3. 专业化与协同设计时代

像SpikeYOLO和SpikingYOLOX这样复杂模型的出现，标志着SNN研究领域已进入一个新的、更成熟的阶段：一个**专业化与协同设计（specialization and co-design）**的时代。最初的、宏观的挑战已基本被克服。学术界不再追问SNNs是否能进行物体检测，也不再仅仅关注延迟这一个问题。相反，研究人员现在正在将SNN范式分解为其组成部分——网络架构、神经元动态、信息编码——并针对脉冲域特有的、已被充分理解的特定问题，设计高度专业化的解决方案。

这代表了与早期仅仅试图模仿ANNs的理念的重大背离。这些较新模型的开发过程揭示了一个清晰的模式。首先，诊断出一个特定的、SNN原生的弱点。对于SpikeYOLO的作者来说，这是由于移植复杂ANN模块引起的架构不稳定性（“脉冲退化”）和量化误差导致的信息丢失。 对于SpikingYOLOX的作者来说，诊断出的弱点是二元脉冲有限的表达能力和标准卷积的局部感受野。   

其次，设计一个高度定制的、SNN特定的解决方案。SpikeYOLO的对策不是小修小补，而是显著的架构简化和一种专门的基于整数的神经元（I-LIF）的设计。SpikingYOLOX的对策同样专业化：一种新的三元神经元模型和集成一个非标准算子（FFC）以实现全局感受野。这种诊断SNN特定问题并设计SNN特定解决方案的迭代过程，正是协同设计的标志。它反映了对脉冲计算基本原理日益增长的信心和更深刻的理解。这种成熟是创造SNNs的关键一步，这些SNNs不仅要匹配其ANN对应物的性能，而且有朝一日可能利用其独特的时序动态，在时空信息至关重要的领域超越它们。焦点已决定性地从转换转向了真正的协同设计。